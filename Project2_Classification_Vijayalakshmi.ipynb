{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'> Project 2 : Buzz Prediction on Twitter\n",
    "\n",
    "Project Description:\n",
    "- There are two different datasets for Regression and Classification tasks. Right-most column in both the datasets is a dependent variable i.e. buzz.\n",
    "- Data description files are also provided for both the datasets.\n",
    "- Deciding which dataset is for which task is part of the project.\n",
    "- Read data into Jupyter notebook, use pandas to import data into a data frame.\n",
    "- Preprocess data: Explore data, check for missing data and apply data scaling. Justify the type of scaling used.\n",
    "\n",
    "Regression Task:\n",
    "- Apply all the regression models you've learned so far. If your model has a scaling parameter(s) use Grid Search to find the best scaling parameter. Use plots and graphs to help you get a better glimpse of the results. \n",
    "- Then use cross-validation to find average training and testing score. \n",
    "- Your submission should have at least the following regression models: KNN regressor, linear regression, Ridge, Lasso, polynomial regression, SVM both simple and with kernels. \n",
    "- Finally, find the best regressor for this dataset and train your model on the entire dataset using the best parameters and predict buzz for the test_set.\n",
    "\n",
    "Classification Task:\n",
    "- Decide about a good evaluation strategy and justify your choice.\n",
    "- Find best parameters for the following classification models: KNN classification, Logistic Regression, Linear Support Vector Machine, Kernelized Support Vector Machine, Decision Tree. \n",
    "- Which model gives the best results?\n",
    "\n",
    "Deliverables:\n",
    "- Submit IPython notebook. Use markdown to provide inline comments for this project.\n",
    "- Rename notebook with your group number and submit only one notebook. Before submitting, make sure everything runs as expected. To check that, restart the kernel (in the menubar, select Kernel > Restart) and then run all cells (in the menubar, select Cell > Run All).\n",
    "- Visualization encouraged.\n",
    "\n",
    "Questions regarding the project:\n",
    "- We have created a discussion board under Projects folder on e-learning. Create threads over there and post your queries related to project there.\n",
    "- There is a high possibility that your classmate has also faced the same problem and knows the solution. So this is an effort to encourage collaborative learning, reducing mails for frequently asked queries and also making all the information available to everyone.\n",
    "- Please check existing threads for your query before creating a new one. It goes without saying that do not share your code or complete solutions there.\n",
    "- We will also answer queries there. We will not be answering any project related queries through the mail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preparation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_table(\"Twitter-Absolute-Sigma-500.data\",sep=\",\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>889</td>\n",
       "      <td>939</td>\n",
       "      <td>960</td>\n",
       "      <td>805</td>\n",
       "      <td>805</td>\n",
       "      <td>1143</td>\n",
       "      <td>1121</td>\n",
       "      <td>549</td>\n",
       "      <td>613</td>\n",
       "      <td>587</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>889</td>\n",
       "      <td>939</td>\n",
       "      <td>960</td>\n",
       "      <td>805</td>\n",
       "      <td>805</td>\n",
       "      <td>1143</td>\n",
       "      <td>1121</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>542</td>\n",
       "      <td>473</td>\n",
       "      <td>504</td>\n",
       "      <td>626</td>\n",
       "      <td>647</td>\n",
       "      <td>795</td>\n",
       "      <td>832</td>\n",
       "      <td>366</td>\n",
       "      <td>288</td>\n",
       "      <td>318</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>542</td>\n",
       "      <td>473</td>\n",
       "      <td>504</td>\n",
       "      <td>626</td>\n",
       "      <td>647</td>\n",
       "      <td>795</td>\n",
       "      <td>832</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>92</td>\n",
       "      <td>99</td>\n",
       "      <td>196</td>\n",
       "      <td>100</td>\n",
       "      <td>184</td>\n",
       "      <td>79</td>\n",
       "      <td>162</td>\n",
       "      <td>66</td>\n",
       "      <td>59</td>\n",
       "      <td>118</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92</td>\n",
       "      <td>99</td>\n",
       "      <td>196</td>\n",
       "      <td>100</td>\n",
       "      <td>184</td>\n",
       "      <td>79</td>\n",
       "      <td>162</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90</td>\n",
       "      <td>87</td>\n",
       "      <td>92</td>\n",
       "      <td>344</td>\n",
       "      <td>184</td>\n",
       "      <td>848</td>\n",
       "      <td>184</td>\n",
       "      <td>83</td>\n",
       "      <td>78</td>\n",
       "      <td>76</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>90</td>\n",
       "      <td>87</td>\n",
       "      <td>92</td>\n",
       "      <td>344</td>\n",
       "      <td>184</td>\n",
       "      <td>848</td>\n",
       "      <td>184</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>169</td>\n",
       "      <td>98</td>\n",
       "      <td>101</td>\n",
       "      <td>90</td>\n",
       "      <td>96</td>\n",
       "      <td>95</td>\n",
       "      <td>185</td>\n",
       "      <td>141</td>\n",
       "      <td>68</td>\n",
       "      <td>85</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>169</td>\n",
       "      <td>98</td>\n",
       "      <td>101</td>\n",
       "      <td>90</td>\n",
       "      <td>96</td>\n",
       "      <td>95</td>\n",
       "      <td>185</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1    2    3    4     5     6    7    8    9  ...    68   69   70  \\\n",
       "0  889  939  960  805  805  1143  1121  549  613  587 ...   1.0  1.0  889   \n",
       "1  542  473  504  626  647   795   832  366  288  318 ...   1.0  1.0  542   \n",
       "2   92   99  196  100  184    79   162   66   59  118 ...   1.0  1.0   92   \n",
       "3   90   87   92  344  184   848   184   83   78   76 ...   1.0  1.0   90   \n",
       "4  169   98  101   90   96    95   185  141   68   85 ...   1.0  1.0  169   \n",
       "\n",
       "    71   72   73   74    75    76   77  \n",
       "0  939  960  805  805  1143  1121  1.0  \n",
       "1  473  504  626  647   795   832  1.0  \n",
       "2   99  196  100  184    79   162  0.0  \n",
       "3   87   92  344  184   848   184  1.0  \n",
       "4   98  101   90   96    95   185  1.0  \n",
       "\n",
       "[5 rows x 78 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = data.iloc[:,0:77]\n",
    "Y_data = data.iloc[:,77]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>889</td>\n",
       "      <td>939</td>\n",
       "      <td>960</td>\n",
       "      <td>805</td>\n",
       "      <td>805</td>\n",
       "      <td>1143</td>\n",
       "      <td>1121</td>\n",
       "      <td>549</td>\n",
       "      <td>613</td>\n",
       "      <td>587</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>889</td>\n",
       "      <td>939</td>\n",
       "      <td>960</td>\n",
       "      <td>805</td>\n",
       "      <td>805</td>\n",
       "      <td>1143</td>\n",
       "      <td>1121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>542</td>\n",
       "      <td>473</td>\n",
       "      <td>504</td>\n",
       "      <td>626</td>\n",
       "      <td>647</td>\n",
       "      <td>795</td>\n",
       "      <td>832</td>\n",
       "      <td>366</td>\n",
       "      <td>288</td>\n",
       "      <td>318</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>542</td>\n",
       "      <td>473</td>\n",
       "      <td>504</td>\n",
       "      <td>626</td>\n",
       "      <td>647</td>\n",
       "      <td>795</td>\n",
       "      <td>832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>92</td>\n",
       "      <td>99</td>\n",
       "      <td>196</td>\n",
       "      <td>100</td>\n",
       "      <td>184</td>\n",
       "      <td>79</td>\n",
       "      <td>162</td>\n",
       "      <td>66</td>\n",
       "      <td>59</td>\n",
       "      <td>118</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92</td>\n",
       "      <td>99</td>\n",
       "      <td>196</td>\n",
       "      <td>100</td>\n",
       "      <td>184</td>\n",
       "      <td>79</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90</td>\n",
       "      <td>87</td>\n",
       "      <td>92</td>\n",
       "      <td>344</td>\n",
       "      <td>184</td>\n",
       "      <td>848</td>\n",
       "      <td>184</td>\n",
       "      <td>83</td>\n",
       "      <td>78</td>\n",
       "      <td>76</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>90</td>\n",
       "      <td>87</td>\n",
       "      <td>92</td>\n",
       "      <td>344</td>\n",
       "      <td>184</td>\n",
       "      <td>848</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>169</td>\n",
       "      <td>98</td>\n",
       "      <td>101</td>\n",
       "      <td>90</td>\n",
       "      <td>96</td>\n",
       "      <td>95</td>\n",
       "      <td>185</td>\n",
       "      <td>141</td>\n",
       "      <td>68</td>\n",
       "      <td>85</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>169</td>\n",
       "      <td>98</td>\n",
       "      <td>101</td>\n",
       "      <td>90</td>\n",
       "      <td>96</td>\n",
       "      <td>95</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1    2    3    4     5     6    7    8    9   ...    67   68   69  \\\n",
       "0  889  939  960  805  805  1143  1121  549  613  587  ...   1.0  1.0  1.0   \n",
       "1  542  473  504  626  647   795   832  366  288  318  ...   1.0  1.0  1.0   \n",
       "2   92   99  196  100  184    79   162   66   59  118  ...   1.0  1.0  1.0   \n",
       "3   90   87   92  344  184   848   184   83   78   76  ...   1.0  1.0  1.0   \n",
       "4  169   98  101   90   96    95   185  141   68   85  ...   1.0  1.0  1.0   \n",
       "\n",
       "    70   71   72   73   74    75    76  \n",
       "0  889  939  960  805  805  1143  1121  \n",
       "1  542  473  504  626  647   795   832  \n",
       "2   92   99  196  100  184    79   162  \n",
       "3   90   87   92  344  184   848   184  \n",
       "4  169   98  101   90   96    95   185  \n",
       "\n",
       "[5 rows x 77 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "1    1.0\n",
       "2    0.0\n",
       "3    1.0\n",
       "4    1.0\n",
       "Name: 77, dtype: float64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_whytouse, sampled_X, Y_whytouse, sampled_y = train_test_split(X_data, Y_data, shuffle = True, test_size = 0.01, random_state=42)\n",
    "#Sampling the dataset so that it doesn't take a lot of time for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "sampled_X = scaler.fit_transform(sampled_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used MinMax scaler to scale the data. StandardScaler couldn't be used as the data has outliers, and so the spread is not uniform for all the data points. StandardScaler will not guarantee balanced feature scales. MinMaxScaler, will rescale the dataset such that all feature values are in the range 0 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(sampled_X, sampled_y, shuffle = True, test_size = 0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kNN Classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n"
     ]
    }
   ],
   "source": [
    "k_range = list(range(1, 16))\n",
    "print(k_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}\n"
     ]
    }
   ],
   "source": [
    "param_grid = dict(n_neighbors=k_range)\n",
    "print(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=k_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(knn, param_grid, cv=10, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1,\n",
       "           n_neighbors=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15],\n",
       "           p=2, weights='uniform'),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9553299492385787\n",
      "{'n_neighbors': 5}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_predict = grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KNN confusion matrix:\n",
      "[[344   5]\n",
      " [ 16  58]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(\"\\nKNN confusion matrix:\")\n",
    "print(confusion_matrix(y_test, knn_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KNN scores:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   non buzz       0.96      0.99      0.97       349\n",
      "       buzz       0.92      0.78      0.85        74\n",
      "\n",
      "avg / total       0.95      0.95      0.95       423\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(\"\\nKNN scores:\")\n",
    "print(classification_report(y_test, knn_predict, target_names=[\"non buzz\", \"buzz\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_knn_predict = grid.predict(X_test)\n",
    "y_knn_train_predict = grid.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train roc_auc_score: 0.95\n",
      "Test roc_auc_score: 0.94 \n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "print('Train roc_auc_score: %.2f'%roc_auc_score(y_knn_train_predict, y_train))\n",
    "print('Test roc_auc_score: %.2f '%roc_auc_score(y_knn_predict, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['knn',\n",
       "  'k = 5',\n",
       "  0.9614213197969543,\n",
       "  0.950354609929078,\n",
       "  0.9509050115962489,\n",
       "  0.9380952380952381]]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_table = [['knn', 'k = 5', grid.score(X_train, y_train), grid.score(X_test, y_test), roc_auc_score(y_knn_train_predict, y_train), roc_auc_score(y_knn_predict, y_test) ]]\n",
    "report_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "logistic = linear_model.LogisticRegression()\n",
    "penalty = ['l1', 'l2']\n",
    "C = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "hyperparameters = dict(C=C, penalty=penalty)\n",
    "grid_lg = GridSearchCV(logistic, hyperparameters, cv=5, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000], 'penalty': ['l1', 'l2']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_lg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9614213197969543\n"
     ]
    }
   ],
   "source": [
    "print(grid_lg.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1000, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "print(grid_lg.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_predict = grid_lg.predict(X_test)\n",
    "lg_train_predict = grid_lg.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LG confusion matrix:\n",
      "[[345   4]\n",
      " [ 11  63]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(\"\\nLG confusion matrix:\")\n",
    "print(confusion_matrix(y_test, lg_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LG scores:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   non buzz       0.97      0.99      0.98       349\n",
      "       buzz       0.94      0.85      0.89        74\n",
      "\n",
      "avg / total       0.96      0.96      0.96       423\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(\"\\nLG scores:\")\n",
    "print(classification_report(y_test, lg_predict, target_names=[\"non buzz\", \"buzz\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train roc_auc_score: 0.96\n",
      "Test roc_auc_score: 0.95 \n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "print('Train roc_auc_score: %.2f'%roc_auc_score(lg_train_predict, y_train))\n",
    "print('Test roc_auc_score: %.2f '%roc_auc_score(lg_predict, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['knn',\n",
       "  'k = 5',\n",
       "  0.9614213197969543,\n",
       "  0.950354609929078,\n",
       "  0.9509050115962489,\n",
       "  0.9380952380952381],\n",
       " ['lg',\n",
       "  'C=1000, Penalty=12',\n",
       "  0.9725888324873097,\n",
       "  0.9645390070921985,\n",
       "  0.9595904151134138,\n",
       "  0.9546998155290961]]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_table =report_table + [['lg', 'C=1000, Penalty=12', grid_lg.score(X_train, y_train), grid_lg.score(X_test, y_test), roc_auc_score(lg_train_predict, y_train), roc_auc_score(lg_predict, y_test) ]]\n",
    "report_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svc_lin = LinearSVC()\n",
    "param_grid = {'C':[0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "grid_svc_lin = GridSearchCV(svc_lin, param_grid, cv = 10, scoring='accuracy')\n",
    "grid_svc_lin.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9573604060913705\n",
      "{'C': 10}\n"
     ]
    }
   ],
   "source": [
    "print(grid_svc_lin.best_score_)\n",
    "print(grid_svc_lin.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_svc_predict = grid_svc_lin.predict(X_test)\n",
    "lin_svc_train_predict = grid_svc_lin.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LinSVC confusion matrix:\n",
      "[[347   2]\n",
      " [ 12  62]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(\"\\nLinSVC confusion matrix:\")\n",
    "print(confusion_matrix(y_test, lin_svc_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LinSVC scores:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   non buzz       0.97      0.99      0.98       349\n",
      "       buzz       0.97      0.84      0.90        74\n",
      "\n",
      "avg / total       0.97      0.97      0.97       423\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(\"\\nLinSVC scores:\")\n",
    "print(classification_report(y_test, lin_svc_predict, target_names=[\"non buzz\", \"buzz\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train roc_auc_score: 0.96\n",
      "Test roc_auc_score: 0.97 \n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "print('Train roc_auc_score: %.2f'%roc_auc_score(lin_svc_train_predict, y_train))\n",
    "print('Test roc_auc_score: %.2f '%roc_auc_score(lin_svc_predict, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['knn',\n",
       "  'k = 5',\n",
       "  0.9614213197969543,\n",
       "  0.950354609929078,\n",
       "  0.9509050115962489,\n",
       "  0.9380952380952381],\n",
       " ['lg',\n",
       "  'C=1000, Penalty=12',\n",
       "  0.9725888324873097,\n",
       "  0.9645390070921985,\n",
       "  0.9595904151134138,\n",
       "  0.9546998155290961],\n",
       " ['lin_svc',\n",
       "  'C=10',\n",
       "  0.9634517766497462,\n",
       "  0.966903073286052,\n",
       "  0.9550435279486403,\n",
       "  0.9676619080779945]]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_table =report_table + [['lin_svc', 'C=10', grid_svc_lin.score(X_train, y_train), grid_svc_lin.score(X_test, y_test), roc_auc_score(lin_svc_train_predict, y_train), roc_auc_score(lin_svc_predict, y_test) ]]\n",
    "report_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kernalized SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'C': [0.1, 1, 10, 100], 'gamma': [0.01, 0.1, 1, 10, 100]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "#Grid Search with Cross-Validation using cv=10\n",
    "param_grid = {'C': [0.1, 1, 10, 100], 'gamma': [0.01, 0.1, 1, 10, 100]}\n",
    "grid_svc = GridSearchCV(SVC(kernel='rbf'), param_grid, cv=10, scoring = 'accuracy', n_jobs=-1)\n",
    "grid_svc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 100, 'gamma': 1}\n",
      "Best cross-validation score: 0.9635\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters: {}\".format(grid_svc.best_params_))\n",
    "print(\"Best cross-validation score: {:.4f}\".format(grid_svc.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_predict = grid_svc.predict(X_test)\n",
    "svc_train_predict = grid_svc.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVC_predict confusion matrix:\n",
      "[[343   6]\n",
      " [ 11  63]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(\"\\nSVC_predict confusion matrix:\")\n",
    "print(confusion_matrix(y_test, svc_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVC scores:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   non buzz       0.97      0.98      0.98       349\n",
      "       buzz       0.91      0.85      0.88        74\n",
      "\n",
      "avg / total       0.96      0.96      0.96       423\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(\"\\nSVC scores:\")\n",
    "print(classification_report(y_test, svc_predict, target_names=[\"non buzz\", \"buzz\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train roc_auc_score: 0.97\n",
      "Test roc_auc_score: 0.94 \n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "print('Train roc_auc_score: %.2f'%roc_auc_score(svc_train_predict, y_train))\n",
    "print('Test roc_auc_score: %.2f '%roc_auc_score(svc_predict, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['knn',\n",
       "  'k = 5',\n",
       "  0.9614213197969543,\n",
       "  0.950354609929078,\n",
       "  0.9509050115962489,\n",
       "  0.9380952380952381],\n",
       " ['lg',\n",
       "  'C=1000, Penalty=12',\n",
       "  0.9725888324873097,\n",
       "  0.9645390070921985,\n",
       "  0.9595904151134138,\n",
       "  0.9546998155290961],\n",
       " ['lin_svc',\n",
       "  'C=10',\n",
       "  0.9634517766497462,\n",
       "  0.966903073286052,\n",
       "  0.9550435279486403,\n",
       "  0.9676619080779945],\n",
       " ['svc',\n",
       "  'C=100, gamma = 1',\n",
       "  0.9776649746192894,\n",
       "  0.9598108747044918,\n",
       "  0.968109759929613,\n",
       "  0.940985015966593]]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_table =report_table + [['svc', 'C=100, gamma = 1', grid_svc.score(X_train, y_train), grid_svc.score(X_test, y_test), roc_auc_score(svc_train_predict, y_train), roc_auc_score(svc_predict, y_test) ]]\n",
    "report_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decsion Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'max_depth': [2, 4, 6, 8, 10, 12]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "param_grid = {'max_depth': [2, 4, 6, 8, 10, 12]}\n",
    "grid_dt = GridSearchCV(DecisionTreeClassifier(), param_grid, cv=10, scoring = 'accuracy')\n",
    "grid_dt.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': 2}\n",
      "Best cross-validation score: 0.9655\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters: {}\".format(grid_dt.best_params_))\n",
    "print(\"Best cross-validation score: {:.4f}\".format(grid_dt.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_predict = grid_dt.predict(X_test)\n",
    "dt_train_predict = grid_dt.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DT_predict confusion matrix:\n",
      "[[342   7]\n",
      " [  9  65]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(\"\\nDT_predict confusion matrix:\")\n",
    "print(confusion_matrix(y_test, dt_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DT scores:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   non buzz       0.97      0.98      0.98       349\n",
      "       buzz       0.90      0.88      0.89        74\n",
      "\n",
      "avg / total       0.96      0.96      0.96       423\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(\"\\nDT scores:\")\n",
    "print(classification_report(y_test, dt_predict, target_names=[\"non buzz\", \"buzz\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train roc_auc_score: 0.96\n",
      "Test roc_auc_score: 0.94 \n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "print('Train roc_auc_score: %.2f'%roc_auc_score(dt_train_predict, y_train))\n",
    "print('Test roc_auc_score: %.2f '%roc_auc_score(dt_predict, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['knn',\n",
       "  'k = 5',\n",
       "  0.9614213197969543,\n",
       "  0.950354609929078,\n",
       "  0.9509050115962489,\n",
       "  0.9380952380952381],\n",
       " ['lg',\n",
       "  'C=1000, Penalty=12',\n",
       "  0.9725888324873097,\n",
       "  0.9645390070921985,\n",
       "  0.9595904151134138,\n",
       "  0.9546998155290961],\n",
       " ['lin_svc',\n",
       "  'C=10',\n",
       "  0.9634517766497462,\n",
       "  0.966903073286052,\n",
       "  0.9550435279486403,\n",
       "  0.9676619080779945],\n",
       " ['svc',\n",
       "  'C=100, gamma = 1',\n",
       "  0.9776649746192894,\n",
       "  0.9598108747044918,\n",
       "  0.968109759929613,\n",
       "  0.940985015966593],\n",
       " ['DT',\n",
       "  'Max Depth = 2',\n",
       "  0.9756345177664975,\n",
       "  0.9621749408983451,\n",
       "  0.9575395556367734,\n",
       "  0.938568376068376]]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_table =report_table + [['DT', 'Max Depth = 2', grid_dt.score(X_train, y_train), grid_dt.score(X_test, y_test), roc_auc_score(dt_train_predict, y_train), roc_auc_score(dt_predict, y_test) ]]\n",
    "report_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = pd.DataFrame(report_table,columns = ['Model name', 'Model parameter', 'Train accuracy', 'Test accuracy', 'Train auc score', 'Test auc score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "report.index = report['Model name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model name</th>\n",
       "      <th>Model parameter</th>\n",
       "      <th>Train accuracy</th>\n",
       "      <th>Test accuracy</th>\n",
       "      <th>Train auc score</th>\n",
       "      <th>Test auc score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>knn</td>\n",
       "      <td>k = 5</td>\n",
       "      <td>0.961421</td>\n",
       "      <td>0.950355</td>\n",
       "      <td>0.950905</td>\n",
       "      <td>0.938095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lg</th>\n",
       "      <td>lg</td>\n",
       "      <td>C=1000, Penalty=12</td>\n",
       "      <td>0.972589</td>\n",
       "      <td>0.964539</td>\n",
       "      <td>0.959590</td>\n",
       "      <td>0.954700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lin_svc</th>\n",
       "      <td>lin_svc</td>\n",
       "      <td>C=10</td>\n",
       "      <td>0.963452</td>\n",
       "      <td>0.966903</td>\n",
       "      <td>0.955044</td>\n",
       "      <td>0.967662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svc</th>\n",
       "      <td>svc</td>\n",
       "      <td>C=100, gamma = 1</td>\n",
       "      <td>0.977665</td>\n",
       "      <td>0.959811</td>\n",
       "      <td>0.968110</td>\n",
       "      <td>0.940985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT</th>\n",
       "      <td>DT</td>\n",
       "      <td>Max Depth = 2</td>\n",
       "      <td>0.975635</td>\n",
       "      <td>0.962175</td>\n",
       "      <td>0.957540</td>\n",
       "      <td>0.938568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model name     Model parameter  Train accuracy  Test accuracy  \\\n",
       "Model name                                                                 \n",
       "knn               knn               k = 5        0.961421       0.950355   \n",
       "lg                 lg  C=1000, Penalty=12        0.972589       0.964539   \n",
       "lin_svc       lin_svc                C=10        0.963452       0.966903   \n",
       "svc               svc    C=100, gamma = 1        0.977665       0.959811   \n",
       "DT                 DT       Max Depth = 2        0.975635       0.962175   \n",
       "\n",
       "            Train auc score  Test auc score  \n",
       "Model name                                   \n",
       "knn                0.950905        0.938095  \n",
       "lg                 0.959590        0.954700  \n",
       "lin_svc            0.955044        0.967662  \n",
       "svc                0.968110        0.940985  \n",
       "DT                 0.957540        0.938568  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the scores of the different models used above, we can determine the best model is Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, Y_data, shuffle = True, test_size = 0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = linear_model.LogisticRegression(penalty = 'l1', C = 1000)\n",
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9663602766985692\n",
      "0.9575012436927013\n"
     ]
    }
   ],
   "source": [
    "train_score=log_reg.score(X_train,y_train)\n",
    "test_score=log_reg.score(X_test,y_test)\n",
    "print(train_score)\n",
    "print(test_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
